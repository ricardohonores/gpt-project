# GPT Project: RAG & Fine-tuning

EspaÃ±ol | [English](README.md)

Proyecto de experimentaciÃ³n con tÃ©cnicas avanzadas de IA: **RAG (Retrieval-Augmented Generation)** y **Fine-tuning** usando modelos de lenguaje locales.

## ğŸ¯ DescripciÃ³n

Este proyecto implementa dos enfoques complementarios para mejorar las capacidades de modelos de lenguaje:

1. **Sistema RAG**: Permite que un LLM local responda preguntas basÃ¡ndose en documentos propios usando bÃºsqueda vectorial
2. **Fine-tuning con QLoRA**: Adapta un modelo pre-entrenado a tareas especÃ­ficas usando cuantizaciÃ³n de 4 bits

## âœ¨ CaracterÃ­sticas

### Sistema RAG (`chatrag_py.py`)
- ğŸ“š Procesa documentos PDF y TXT
- ğŸ” BÃºsqueda semÃ¡ntica con FAISS
- ğŸ¤– IntegraciÃ³n con Ollama para inferencia local
- ğŸ’¬ Interfaz interactiva de preguntas y respuestas
- ğŸ“ Muestra fuentes de informaciÃ³n en cada respuesta

### Fine-tuning (`finetuning.py`)
- âš¡ QLoRA (Quantized Low-Rank Adaptation) para entrenar con poca VRAM
- ğŸ¯ CuantizaciÃ³n de 4 bits
- ğŸ’¾ Guarda solo adaptadores (pesos ligeros)
- ğŸ”§ Configurable para GPU o CPU

## ğŸ“‹ Requisitos

- Python 3.8+
- [Ollama](https://ollama.ai/) instalado y corriendo
- Modelo `gpt-oss:20b` descargado en Ollama
- GPU con CUDA (opcional, pero recomendado para fine-tuning)

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/ricardohonores/gpt-project.git
cd gpt-project
```

### 2. Crear entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias

**Para el sistema RAG:**
```bash
pip install langchain-community langchain-core transformers accelerate sentence-transformers faiss-cpu pypdf
```

**Para fine-tuning (adicional):**
```bash
pip install datasets peft trl bitsandbytes
```

**Para GPU (opcional):**
```bash
pip install faiss-gpu
```

### 4. Instalar y configurar Ollama
```bash
# Instalar Ollama (si no lo tienes)
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar el modelo
ollama pull gpt-oss:20b
```

## ğŸ’» Uso

### Sistema RAG

1. **Coloca tus documentos** en la carpeta `mis_documentos/` (archivos .txt o .pdf)

2. **Inicia Ollama** (en otra terminal):
```bash
ollama serve
```

3. **Ejecuta el sistema RAG**:
```bash
python chatrag_py.py
```

4. **Haz preguntas** interactivamente. Escribe `salir` para terminar.

**Ejemplo:**
```
Tu pregunta: Â¿QuÃ© es la IA generativa?

--- Respuesta ---
La IA generativa es una inteligencia artificial que crea contenido nuevo...

--- Fuentes ---
-> Fuente: /path/to/document.pdf, PÃ¡g: 5
```

### Fine-tuning

1. **Prepara tu dataset** en formato JSONL (`dataset.jsonl`):
```json
{"instruction": "Pregunta o tarea", "output": "Respuesta esperada"}
{"instruction": "Otra pregunta", "output": "Otra respuesta"}
```

2. **Ejecuta el entrenamiento**:
```bash
python finetuning.py
```

3. **Los adaptadores se guardan** en `./gpt_oss_fine_tuned/`

## ğŸ“ Estructura del Proyecto

```
gpt-project/
â”œâ”€â”€ chatrag_py.py          # Sistema RAG completo
â”œâ”€â”€ finetuning.py          # Script de fine-tuning con QLoRA
â”œâ”€â”€ dataset.jsonl          # Dataset de ejemplo
â”œâ”€â”€ CLAUDE.md              # DocumentaciÃ³n tÃ©cnica (inglÃ©s)
â”œâ”€â”€ CLAUDE.es.md           # DocumentaciÃ³n tÃ©cnica (espaÃ±ol)
â”œâ”€â”€ README.md              # README en inglÃ©s
â”œâ”€â”€ README.es.md           # Este archivo (espaÃ±ol)
â”œâ”€â”€ .gitignore             # Archivos ignorados por git
â””â”€â”€ mis_documentos/        # Carpeta de documentos para RAG
    â”œâ”€â”€ *.pdf
    â””â”€â”€ *.txt
```

## ğŸ”§ ConfiguraciÃ³n

### Sistema RAG
Edita las siguientes variables en `chatrag_py.py`:
```python
DOCS_FOLDER = "/ruta/a/tus/documentos"
EMBEDDINGS_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
OLLAMA_MODEL_NAME = "gpt-oss:20b"
```

### Fine-tuning
Edita las siguientes variables en `finetuning.py`:
```python
OLLAMA_MODEL_NAME = "gpt-oss:20b"
DATASET_FILE = "dataset.jsonl"
OUTPUT_DIR = "./gpt_oss_fine_tuned"
```

## ğŸ¤” Â¿RAG o Fine-tuning?

| CaracterÃ­stica | RAG | Fine-tuning |
|----------------|-----|-------------|
| **Modifica el modelo** | âŒ No | âœ… SÃ­ |
| **Requiere entrenamiento** | âŒ No | âœ… SÃ­ |
| **Documentos dinÃ¡micos** | âœ… SÃ­ | âŒ No |
| **Muestra fuentes** | âœ… SÃ­ | âŒ No |
| **Cambia comportamiento** | âŒ No | âœ… SÃ­ |
| **Uso de memoria** | ğŸŸ¢ Bajo | ğŸŸ¡ Medio |

**Usa RAG cuando:** Necesites responder preguntas sobre documentos especÃ­ficos o conocimiento que cambia frecuentemente.

**Usa Fine-tuning cuando:** Quieras que el modelo aprenda un estilo especÃ­fico, dominio tÃ©cnico o nuevos patrones de comportamiento.

## ğŸ“š DocumentaciÃ³n Adicional

Para detalles tÃ©cnicos sobre la arquitectura y configuraciÃ³n, consulta [CLAUDE.es.md](CLAUDE.es.md).

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para uso educativo y experimental.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. SiÃ©ntete libre de abrir issues o pull requests.
